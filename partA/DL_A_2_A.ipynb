{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCFDgD1ASH4n"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import wandb\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "wandb.login()\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Function to display a single image\n",
        "def imshow(img, title=None):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Function to visualize a single image from a DataLoader\n",
        "def visualize_single_image(loader, title=None):\n",
        "    data_iter = iter(loader)\n",
        "    images, labels = next(data_iter)\n",
        "    imshow(images[8], title=title)\n",
        "\n",
        "\n",
        "\n",
        "def get_data_loaders(train_data_dir, test_data_dir, data_augmentation):\n",
        "    # Define default transform\n",
        "    default_transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(256),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225]),\n",
        "\n",
        "    ])\n",
        "\n",
        "    # Define transform for data augmentation\n",
        "\n",
        "    augment_transform = transforms.Compose([\n",
        "        transforms.RandomRotation(degrees=(5,5), fill=(0,)),\n",
        "        transforms.RandomHorizontalFlip(p=1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225]),\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(256)\n",
        "\n",
        "    ])\n",
        "\n",
        "\n",
        "    # Load the dataset without augmentation\n",
        "    train_dataset = datasets.ImageFolder(root=train_data_dir, transform=default_transform)\n",
        "\n",
        "    # Separate classes\n",
        "    class_to_idx = train_dataset.class_to_idx\n",
        "    idx_to_class = {idx: class_name for class_name, idx in class_to_idx.items()}\n",
        "\n",
        "    # Create a dictionary to hold data indices for each class\n",
        "    class_indices = defaultdict(list)\n",
        "    for idx, (_, label) in enumerate(train_dataset.samples):\n",
        "        class_indices[label].append(idx)\n",
        "\n",
        "    # Set aside 20% of data from each class for validation\n",
        "    validation_indices = []\n",
        "    train_indices = []\n",
        "    for class_idx, indices in class_indices.items():\n",
        "        num_validation = int(0.2 * len(indices))\n",
        "        random.shuffle(indices)  # Shuffle indices to ensure randomness\n",
        "        validation_indices.extend(indices[:num_validation])\n",
        "        train_indices.extend(indices[num_validation:])\n",
        "\n",
        "    # Create PyTorch data loaders for the initial dataset\n",
        "    train_loader = DataLoader(Subset(train_dataset, train_indices), batch_size=32, shuffle=True)\n",
        "    validation_loader = DataLoader(Subset(train_dataset, validation_indices), batch_size=32, shuffle=True)\n",
        "\n",
        "    # Load test data\n",
        "    test_dataset = datasets.ImageFolder(root=test_data_dir, transform=default_transform)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "    #visualize_single_image(train_loader, title='Without Augmentation')\n",
        "\n",
        "    # If data augmentation is enabled, create augmented data loader\n",
        "    if data_augmentation:\n",
        "        # Create DataLoader for augmented training data using train_indices\n",
        "        augmented_dataset = datasets.ImageFolder(root=train_data_dir, transform=augment_transform)\n",
        "        augmented_loader = DataLoader(Subset(augmented_dataset, train_indices), batch_size=32, shuffle=True)\n",
        "        # Combine original training data and augmented data\n",
        "\n",
        "        #visualize_single_image(augmented_loader, title='With Augmentation')\n",
        "        combined_dataset = ConcatDataset([train_loader.dataset, augmented_loader.dataset])\n",
        "        train_loader = DataLoader(combined_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "    return train_loader, validation_loader, test_loader\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWXkigEsS7J7"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, validation_loader, criterion, optimizer, num_epochs, device):\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "        epoch_progress = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=False)\n",
        "        for images, labels in epoch_progress:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_predictions += labels.size(0)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "            epoch_progress.set_postfix({'Loss': running_loss / len(train_loader), 'Accuracy': 100 * correct_predictions / total_predictions})\n",
        "        epoch_progress.close()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in validation_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Calculate validation loss and accuracy\n",
        "        val_loss /= len(validation_loader)\n",
        "        val_accuracy = 100 * val_correct / val_total\n",
        "        accuracy = 100 * correct_predictions / total_predictions\n",
        "        loss = running_loss / len(train_loader)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], accuracy: {accuracy:.2f}, loss: {loss:.2f}, val_accuracy: {val_accuracy:.2f}, val_loss: {val_loss:.2f}\")\n",
        "\n",
        "        # Log to Weights & Biases\n",
        "        wandb.log({\n",
        "            \"Epoch\": epoch + 1,\n",
        "            \"Accuracy\": round(accuracy, 2),\n",
        "            \"Loss\": round(loss, 2),\n",
        "            \"Validation Accuracy\": round(val_accuracy, 2),\n",
        "            \"Validation Loss\": round(val_loss, 2)\n",
        "        })\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vseE85qTLIX"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels.squeeze()).sum().item()\n",
        "\n",
        "    accuracy = (correct / total) * 100\n",
        "    print(f\"Accuracy on test set: {accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_sample_predictions(model, test_loader, device, num_samples=10):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        fig, axs = plt.subplots(10, 3, figsize=(15, 30))\n",
        "        classes_seen = set()\n",
        "        samples_per_class = num_samples // 10\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            for image, label, pred in zip(images, labels, predicted):\n",
        "                class_idx = label.item()\n",
        "                if class_idx not in classes_seen and len(classes_seen) < 10:\n",
        "                    classes_seen.add(class_idx)\n",
        "                    sample_idx = len(classes_seen) - 1\n",
        "                    image = image.cpu()  # Move image to CPU\n",
        "                    axs[sample_idx, 0].text(0.5, 0.5, f\"Actual: {class_idx}\", ha='center')\n",
        "                    axs[sample_idx, 0].axis('off')\n",
        "                    axs[sample_idx, 1].imshow(image.permute(1, 2, 0).numpy())\n",
        "                    axs[sample_idx, 1].axis('off')\n",
        "                    axs[sample_idx, 2].text(0.5, 0.5, f\"Predicted: {pred.item()}\", ha='center')\n",
        "                    axs[sample_idx, 2].axis('off')\n",
        "            if len(classes_seen) >= 10:\n",
        "                break\n",
        "\n",
        "    plt.tight_layout()\n",
        "    image = wandb.Image(plt)\n",
        "    wandb.log({\"Sample Predictions\": image})\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ZQ_gFjyz5Os7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hXq1GCPTM85"
      },
      "outputs": [],
      "source": [
        "def CNN(input_channels, num_classes, num_filters, filter_size, activation, batch_norm, dropout, filter_multiplier, dense_neurons):\n",
        "    # Define activation function\n",
        "    act_fn = {\n",
        "        'ReLU': nn.ReLU(),\n",
        "        'GELU': nn.GELU(),\n",
        "        'SiLU': nn.SiLU(),\n",
        "        'Mish': nn.Mish()\n",
        "    }[activation]\n",
        "\n",
        "    layers = []\n",
        "    in_channels = input_channels\n",
        "    out_channels = num_filters\n",
        "    for i in range(5):\n",
        "        layers.extend([\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=filter_size[i], stride=1, padding=1),\n",
        "            act_fn,\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        ])\n",
        "        if batch_norm:\n",
        "            layers.append(nn.BatchNorm2d(out_channels))\n",
        "        if dropout > 0:\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "        in_channels = out_channels\n",
        "        out_channels = int(out_channels * filter_multiplier)\n",
        "\n",
        "    # Calculate the size of the output after the convolutional layers\n",
        "    x = torch.randn(1, input_channels, 256, 256)\n",
        "    for layer in layers:\n",
        "        x = layer(x)\n",
        "    conv_out_size = x.size(1) * x.size(2) * x.size(3)\n",
        "\n",
        "    model = nn.Sequential(\n",
        "        *layers,\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(conv_out_size, dense_neurons),\n",
        "        act_fn,\n",
        "        nn.Linear(dense_neurons, num_classes)\n",
        "    )\n",
        "\n",
        "    return model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbnKlkt7TOmi"
      },
      "outputs": [],
      "source": [
        "# Define the wandb configuration\n",
        "sweep_config = {\n",
        "    \"method\": \"bayes\",\n",
        "    \"metric\": {\"goal\": \"maximize\", \"name\": \"Validation Accuracy\"},\n",
        "    \"parameters\": {\n",
        "        \"num_filters\": {\"values\": [32, 64, 128]},\n",
        "        \"activation\": {\"values\": ['ReLU', 'GELU', 'SiLU', 'Mish']},\n",
        "        \"filter_size_1\": {\"values\": [2, 3, 5]},\n",
        "        \"filter_size_2\": {\"values\": [2, 3, 5]},\n",
        "        \"filter_size_3\": {\"values\": [2, 3, 5]},\n",
        "        \"filter_size_4\": {\"values\": [2, 3, 5]},\n",
        "        \"filter_size_5\": {\"values\": [2, 3, 5]},\n",
        "        \"filter_multiplier\": {\"values\": [1, 2, 0.5]},\n",
        "        \"data_augmentation\": {\"values\": ['Yes', 'No']},\n",
        "        \"batch_normalization\": {\"values\": ['Yes', 'No']},\n",
        "        \"dropout\": {\"values\": [0.2, 0.3]},\n",
        "        \"dense_neurons\": {\"values\": [128, 256, 512, 1024]},\n",
        "        \"epoch\":{\"values\": [5,10]},\n",
        "        \"learning_rate\":{\"values\":[0.001,0.0001]}\n",
        "    }\n",
        "}\n",
        "\n",
        "def train():\n",
        "    # Initialize wandb\n",
        "    wandb.init()\n",
        "    # Set your hyperparameters from wandb config\n",
        "    config = wandb.config\n",
        "\n",
        "    wandb.run.name = f'num_filters_{config.num_filters}_activation_{config.activation}_filter_multiplier_{config.filter_multiplier}_data_augmentation_{config.data_augmentation}_batch_normalization_{config.batch_normalization}_dropout_{config.dropout}_dense_neurons_{config.dense_neurons}_learning_rate_{config.learning_rate}_epoch_{config.epoch}'\n",
        "\n",
        "    data_augmentation=False\n",
        "    if(config.data_augmentation=='Yes'):\n",
        "        data_augmentation=True\n",
        "\n",
        "    batch_normalization=False\n",
        "    if(config.batch_normalization=='Yes'):\n",
        "        batch_normalization=True\n",
        "\n",
        "    # Example usage:\n",
        "    train_data_dir = \"/content/drive/MyDrive/Deep Learning/A2/inaturalist_12K/train\"\n",
        "    test_data_dir = \"/content/drive/MyDrive/Deep Learning/A2/inaturalist_12K/val\"\n",
        "    train_loader, validation_loader, test_loader = get_data_loaders(train_data_dir, test_data_dir, data_augmentation)\n",
        "\n",
        "    print(f\"Training set size: {len(train_loader.dataset)}\")\n",
        "    print(f\"Validation set size: {len(validation_loader.dataset)}\")\n",
        "    print(f\"Test set size: {len(test_loader.dataset)}\")\n",
        "    filter_size=[config.filter_size_1,config.filter_size_2,config.filter_size_3,config.filter_size_4,config.filter_size_5]\n",
        "    # Example usage:\n",
        "    model = CNN(\n",
        "        input_channels=3,\n",
        "        num_classes=10,\n",
        "        num_filters=config.num_filters,\n",
        "        filter_size=filter_size,\n",
        "        activation=config.activation,\n",
        "        batch_norm=batch_normalization,\n",
        "        dropout=config.dropout,\n",
        "        filter_multiplier=config.filter_multiplier,\n",
        "        dense_neurons=config.dense_neurons\n",
        "    )\n",
        "\n",
        "    #model = CNN(input_channels=3, num_classes=10, num_filters=32, filter_size=3, activation='mish', batch_norm=True, dropout=0.2, filter_multiplier=1, dense_neurons=256)\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "    model=train_model(model, train_loader, validation_loader, criterion, optimizer, config.epoch, device)\n",
        "\n",
        "    #Evaluate on Test data\n",
        "    evaluate_model(model, test_loader, device)\n",
        "\n",
        "    #Plot Test prediction\n",
        "    plot_sample_predictions(model, test_loader, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r07plzi7TRjv"
      },
      "outputs": [],
      "source": [
        "# Initialize wandb sweep\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"deep_learn_assignment_2\" ,entity=\"cs23m063\")\n",
        "\n",
        "# Run wandb agent to execute the sweep\n",
        "wandb.agent(sweep_id, function=train, count =1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1pCV8Oe3V4fSbpnpp_4dqpvuBQOsNpF4i",
      "authorship_tag": "ABX9TyOugPksxhzXoBAvxKasjQMU"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}